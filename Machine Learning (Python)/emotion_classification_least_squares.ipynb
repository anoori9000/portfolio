{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "985540c0",
   "metadata": {},
   "source": [
    "\n",
    "# A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13860dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Squares Classifier Weights:\n",
      " [[ 0.94366942]\n",
      " [ 0.21373778]\n",
      " [ 0.26641775]\n",
      " [-0.39221373]\n",
      " [-0.00538552]\n",
      " [-0.01764687]\n",
      " [-0.16632809]\n",
      " [-0.0822838 ]\n",
      " [-0.16644364]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "in_data = loadmat('face_emotion_data.mat')\n",
    "x = in_data['X']\n",
    "y = in_data['y']\n",
    "\n",
    "w_opt = np.linalg.inv(x.T@x)@x.T@y\n",
    "print(\"Least Squares Classifier Weights:\\n\",w_opt)\n",
    "y_hat = np.sign(x@w_opt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ed534f",
   "metadata": {},
   "source": [
    "# B)\n",
    "\n",
    "The $\\hat{w}$ vector indicates the weight that is to be placed on a certain distance measurement from the $X$ matrix. Since $X$ is m-by-n, each row of $X$ indicates a specific individual's measurements, and each column corresponds to a specific type of measurement from each individual. When you get a new image, take those weights and multiply them by the corresponding distance measurement and sum the results (as in, inner product $x^{T}\\hat{w}$). The sign of the result will tell you whether the person is sad or happy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac918df",
   "metadata": {},
   "source": [
    "# C)\n",
    "\n",
    "$w_1=0.94366942$ is the most significant because it has the largest magnitude - more than double the other weights. The second most significant would be $w_4=-0.39221373$ and the third is $w_3=0.26641775$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e56602c",
   "metadata": {},
   "source": [
    "# D)\n",
    "\n",
    "We should choose the three most significant weights from the previous question because these have the most impact on whether we determine a face is happy or sad. \n",
    "\n",
    "To design the classifier, we want only features 1, 3, and 4, so we can re-train the classifier to get a new weight vector $\\hat{w}$ by isolating the specific mesasurements (columns of $X$) that correspond to those weights. From there, you can calculate the classifier $\\hat{y}=X\\hat{w}$ and use the sign of the result to classify the emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96fb080a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of partitioned X:\n",
      " (128, 3)\n",
      "Least Squares Classifier Weights for partitioned X:\n",
      " [[ 0.70546316]\n",
      " [ 0.8737872 ]\n",
      " [-0.78805643]]\n"
     ]
    }
   ],
   "source": [
    "x_partition = x[:, [0, 2, 3]]\n",
    "print(\"Dimensions of partitioned X:\\n\",x_partition.shape)\n",
    "\n",
    "w_opt_2 = np.linalg.inv(x_partition.T@x_partition)@x_partition.T@y\n",
    "\n",
    "print(\"Least Squares Classifier Weights for partitioned X:\\n\", w_opt_2)\n",
    "\n",
    "y_hat_2 = np.sign(x_partition@w_opt_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30da596d",
   "metadata": {},
   "source": [
    "# E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f1fb73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors (9 features):  3\n",
      "%Error (9 features):  2.34375\n",
      "Errors (3 features):  8\n",
      "%Error (3 features):  6.25\n"
     ]
    }
   ],
   "source": [
    "error_vec = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat, y))]\n",
    "print(\"Errors (9 features): \", sum(error_vec))\n",
    "print(\"%Error (9 features): \", 100*sum(error_vec)/128)\n",
    "\n",
    "error_vec_2 = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat_2, y))]\n",
    "print(\"Errors (3 features): \", sum(error_vec_2))\n",
    "print(\"%Error (3 features): \", 100*sum(error_vec_2)/128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d72a9d",
   "metadata": {},
   "source": [
    "# F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ccaceeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Range: 1-16\n",
      "Errors:  1\n",
      "%Error:  6.25\n",
      "\n",
      "Range: 17-32\n",
      "Errors:  1\n",
      "%Error:  6.25\n",
      "\n",
      "Range: 33-48\n",
      "Errors:  2\n",
      "%Error:  12.5\n",
      "\n",
      "Range: 49-64\n",
      "Errors:  1\n",
      "%Error:  6.25\n",
      "\n",
      "Range: 65-80\n",
      "Errors:  0\n",
      "%Error:  0.0\n",
      "\n",
      "Range: 81-96\n",
      "Errors:  1\n",
      "%Error:  6.25\n",
      "\n",
      "Range: 97-112\n",
      "Errors:  0\n",
      "%Error:  0.0\n",
      "\n",
      "Range: 113-128\n",
      "Errors:  0\n",
      "%Error:  0.0\n",
      "\n",
      "Total number of errors:  6\n",
      "Error rate:  0.046875\n",
      "%Error:  4.6875\n"
     ]
    }
   ],
   "source": [
    "def crossValidate(x_hold, y_hold, x_train, y_train):\n",
    "    ## Compute least squares estimate\n",
    "    w_opt = np.linalg.inv(x_train.T@x_train)@x_train.T@y_train\n",
    "    ## Compute estimated labels\n",
    "    y_hat = np.sign(x_hold@w_opt)\n",
    "    ## Compare holdout to trained results\n",
    "    error_vec = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat, y_hold))]\n",
    "    print(\"Errors: \", sum(error_vec))\n",
    "    print(\"%Error: \", 100*sum(error_vec)/16)\n",
    "    return sum(error_vec)\n",
    "\n",
    "error = 0\n",
    "for i in range (0, 128, 16):\n",
    "    x_hold = x[i:i+16,:]\n",
    "    y_hold = y[i:i+16,:]\n",
    "    x_train = np.concatenate( (x[:i,:], x[i+16:,:]) )\n",
    "    y_train = np.concatenate( (y[:i,:], y[i+16:,:]) )\n",
    "    print(\"\\nRange: \" + str(i+1) + \"-\" + str(i+16))\n",
    "    error = error + crossValidate(x_hold, y_hold, x_train, y_train)\n",
    "print(\"\\nTotal number of errors: \", error)\n",
    "print(\"Error rate: \", (error/16)/8)\n",
    "print(\"%Error: \", 100*(error/16)/8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
